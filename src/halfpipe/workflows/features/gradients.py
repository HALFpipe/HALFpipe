# -*- coding: utf-8 -*-
# emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode: nil -*-
# vi: set ft=python sts=4 ts=4 sw=4 et:

from pathlib import Path
from os.path import abspath
#from typing import Literal, Sequence

#from nipype.algorithms import confounds as nac
from nipype.interfaces import utility as niu
from nipype.pipeline import engine as pe

from ...interfaces.result.datasink import ResultdictDatasink
from ...interfaces.result.make import MakeResultdicts
from ...utils.format import format_workflow
#from ..constants import Constants

from ..memory import MemoryCalculator

from nipype import Node, Workflow
from halfpipe.interfaces.gradients import Gradients
from halfpipe.model.feature import Feature

##############
# DRAFT CODE #
##############
# This code is a draft to implement brainspace gradients in HALFpipe
# TODO connect w/ atlas_based_connectivity wf
# TODO check outputs/run in halfpipe

def init_gradients_wf(
    workdir: str | Path,
    x, # TODO remove this & link I/O properly
    feature: Feature | None = None,
    memcalc: MemoryCalculator | None = None,
) -> pe.Workflow:
    """
    create workflow for gradients
    """
    ###########################
    # Fill in optional inputs #
    ###########################
    memcalc = MemoryCalculator.default() if memcalc is None else memcalc

    # Hard for me to understand this
    # where is feature name defined? 
    #   user defines it in UI (?)
    # where is feature generated? 
    #   in UI from spec file
    if feature is not None:
        name = f"{format_workflow(feature.name)}_wf"
    else:
        name = "gradients_wf"
    workflow = pe.Workflow(name=name)

    ###################
    # SETUP I/O NODES #
    ###################
    # input node fields go into an identity interface that means the node does nothing to the values
    # here define all the inputs that will go through workflow
    # inputs will come from two places:
        # entries to Spec file/UI input via the Feature
        # things that were computed by halfpipe from another node
    inputnode = pe.Node(
        niu.IdentityInterface(
            # Adding a field here means also adding it in model > tags > resultdict.py (validates allowed tags)
            fields=[
                # these will come from prev node
                "tags",
                "vals",
                "metadata",

                # gradients params
                # TODO cut these down/consider necessary
                "n_components",
                "approach",
                "kernel",
                "random_state",
                "alignment",

                "x", # only one not to come from user at init of halfpipe (generated by connectivity wf)
                "gamma",
                "sparsity",
                "n_iter",
                "reference",
            ]
        ),
        name="inputnode",
    )
    outputnode = pe.Node(niu.IdentityInterface(fields=["resultdicts"]), name="outputnode")

    if Feature is not None:
        # Why would the Feature be None?
        inputnode.inputs.n_components = feature.n_components
        inputnode.inputs.approach = feature.approach
        inputnode.inputs.kernel = feature.kernel
        inputnode.inputs.random_state = feature.random_state
        inputnode.inputs.alignment = feature.alignment

        inputnode.inputs.gamma = feature.gamma
        inputnode.inputs.sparsity = feature.sparsity
        inputnode.inputs.n_iter = feature.n_iter
        inputnode.inputs.reference = feature.reference

    # TODO how do I collect x (connectivity matrix) from previous node of halfpipe?
    inputnode.inputs.x = x

    # how to know what keys are needed/wanted?
    # here adding new keys to resultdict 
    make_resultdicts = pe.Node(
        MakeResultdicts(
            tagkeys=["feature", "reference"], # tag keys go to filename (needs to be changed in model.tags.resultdict.py)
            imagekeys=["lambdas", "gradients", "aligned"], # 'aligned' is an optional output so this might be wrong way
        ),
        name="make_resultdicts",
    )
    if feature is not None:
        make_resultdicts.inputs.feature = feature.name

    # Connect inputnode values to relevant make_resultdicts outputs
    workflow.connect(inputnode, "tags", make_resultdicts, "tags")
    workflow.connect(inputnode, "vals", make_resultdicts, "vals")
    workflow.connect(inputnode, "metadata", make_resultdicts, "metadata")

    # TODO do we care to connect all the feature inputs to make_resultdicts?
    #   e.g. under metadata keys for record keeping? (no for now)

    workflow.connect(make_resultdicts, "resultdicts", outputnode, "resultdicts")

    #
    resultdict_datasink = pe.Node(ResultdictDatasink(base_directory=workdir), name="resultdict_datasink")
    workflow.connect(make_resultdicts, "resultdicts", resultdict_datasink, "indicts")

    #######################################
    # CONNECT I/O NODES W/ GRADIENTS NODE #
    #######################################

    gradientsnode = pe.Node(
        Gradients(),
        name = "gradients",
        mem_gb = memcalc.series_std_gb,
    )

    # connect inputnode values
    workflow.connect(inputnode, "n_components", gradientsnode, "n_components")
    workflow.connect(inputnode, "approach", gradientsnode, "approach")
    workflow.connect(inputnode, "kernel", gradientsnode, "kernel")
    workflow.connect(inputnode, "random_state", gradientsnode, "random_state")
    workflow.connect(inputnode, "alignment", gradientsnode, "alignment")
    workflow.connect(inputnode, "x", gradientsnode, "x")
    workflow.connect(inputnode, "gamma", gradientsnode, "gamma")
    workflow.connect(inputnode, "sparsity", gradientsnode, "sparsity")
    workflow.connect(inputnode, "n_iter", gradientsnode, "n_iter")
    workflow.connect(inputnode, "reference", gradientsnode, "reference")

    # connect resultdicts (how does this interact/correspond w the dictionary tags?)
    workflow.connect(gradientsnode, "lambdas", make_resultdicts, "lambdas")
    workflow.connect(gradientsnode, "gradients", make_resultdicts, "gradients")
    workflow.connect(gradientsnode, "aligned", make_resultdicts, "aligned")

    return workflow
